# ❓ 给 CN 总工程师的 20 个问题

<aside>
🎯

**背景**：基于对 CreoNow 产品定义、技术架构、记忆系统和 Agentic 能力层的深度研究，以下是我最想问 CN 总工程师的 20 个问题。这些问题覆盖架构决策、技术取舍、产品边界、用户体验和商业化等多个维度，目的是找出当前设计中 **尚未回答的关键不确定性**。

</aside>

---

## 🏗️ 架构与技术决策

### Q1：上下文引擎的 token 预算分配是静态的还是动态的？

分层上下文系统中，Rules / Settings / Retrieved / Immediate 四层各自的 token 预算是固定比例，还是根据当前任务动态调整？比如，当用户在写一个全新场景（没有太多历史上下文可召回）时，Retrieved 层的预算是否会自动让渡给 Immediate 层？如果是动态的，分配算法的核心逻辑是什么？

### Q2：知识图谱的更新策略是什么？

知识图谱是 CN 的核心数据结构之一，但创作是一个不断变化的过程——角色会成长、设定会修改、剧情会推翻重来。问题是：

- 知识图谱的更新是**纯手动**（用户维护）、**纯自动**（AI 从文本中提取并更新）、还是**混合模式**？
- 如果有自动更新，如何避免 AI 误把「草稿中的临时想法」当成「已确定的设定」写入图谱？
- 当用户删除或大幅修改某章内容时，知识图谱是否会自动回退相关变更？

### Q3：本地 embedding 模型的选型考量是什么？

情景记忆的语义检索需要 embedding 能力。作为一个 Electron 本地应用：

- 是计划在本地运行轻量 embedding 模型（如 all-MiniLM-L6-v2），还是依赖远程 API？
- 如果本地运行，如何在低配 Windows 机器上保证性能？
- embedding 模型对**中文创作内容**的效果如何？是否需要针对中文文学场景做微调？

### Q4：SQLite 能撑住多大规模的项目？

一个长篇小说可能有 50+ 万字、数百个章节、数千次 AI 交互记录。SQLite 作为本地存储：

- 预估的单项目数据库大小上限是多少？
- 情景记忆 + 知识图谱 + 版本快照的存储增长曲线是怎样的？
- 是否考虑过分库策略（如每个项目一个 SQLite 文件）？
- 在大项目中，全文语义检索的延迟能控制在什么范围内？

---

## 🧠 记忆系统

### Q5：情景记忆的「隐式反馈」提取有多可靠？

设计中提到通过 editDistance、用户选择行为等隐式信号来判断 AI 输出质量。但实际情况远比理论复杂：

- 用户修改 AI 输出可能不是因为「不好」，而是因为「想往不同方向发展」——如何区分？
- 用户直接接受输出可能是因为「赶时间」而非「满意」——这种噪声如何过滤？
- 是否有计划通过 A/B 测试或用户研究来验证隐式反馈的实际准确率？

### Q6：语义记忆的蒸馏质量如何保证？

从情景记忆到语义记忆的蒸馏是一个关键环节。如果蒸馏出错误的规则（比如「用户偏好长句」实际上是「用户在特定场景下偶尔用长句」），会持续污染后续所有 AI 输出。

- 蒸馏过程是用 LLM 做的吗？还是基于统计规则？
- 如何设定「统计显著性」的阈值——多少个一致的情景记忆才能蒸馏出一条可信的语义记忆？
- 有没有「沙盒模式」让用户在语义记忆生效前先预览效果？

### Q7：冷启动问题怎么解决？

新用户刚开始使用 CN 时，记忆系统是空的。这意味着：

- AI 输出在初期会偏「通用」，可能让用户觉得和 ChatGPT 没什么区别
- 需要多少次交互才能积累出有价值的个性化记忆？（10 次？50 次？200 次？）
- 是否考虑过 **引导式冷启动**——比如让用户在首次使用时填写一份「创作偏好问卷」，直接初始化语义记忆？
- 是否支持从用户已有的作品中批量导入并分析风格？

---

## 🤖 Agentic 能力

### Q8：任务规划器的「智能」有多智能？

任务规划器需要将高层指令分解为步骤序列。这个分解能力本身依赖 LLM，而 LLM 在规划任务上并不总是可靠的。

- 规划器的 prompt 是如何设计的？是否有固定的规划模板库？
- 对于模糊指令（如「帮我把这章写得更好」），规划器如何决定具体做什么？
- 规划失败（生成了不合理的步骤序列）的回退机制是什么？
- 是否有计划收集用户的规划反馈来持续优化规划器？

### Q9：反思循环的成本如何向用户解释？

每轮反思意味着额外的 API 调用和等待时间。对于按 token 计费的 AI 服务：

- 用户是否能看到每次操作的 token 消耗？
- 反思循环是否计入用户的配额/费用？
- 如果反思循环使操作时间翻倍，用户是否会因为等待而关闭反思功能？有没有「后台反思」的方案（先展示初稿，反思完成后提示用户有改进版本）？

### Q10：主动感知的误报率能控制在多少？

主动感知（一致性守卫、伏笔追踪、节奏分析）的价值取决于**精准度**。如果频繁误报：

- 用户会失去信任，最终关闭功能
- 打断创作心流

你们对误报率的目标是多少？有没有做过内部测试？在什么类型的作品上误报率最高（如魔幻现实主义作品中的「不一致」可能是故意为之）？

---

## 📝 创作场景与产品边界

### Q11：CN 的目标用户到底是谁？

产品定义中提到了小说、剧本、自媒体文章。但这三类创作的差异巨大：

- **小说**：长篇、强叙事、需要知识图谱和伏笔追踪
- **剧本**：格式化要求高、多角色对白驱动
- **自媒体文章**：短篇、强观点、SEO 驱动

CN 是打算一开始就覆盖所有这些场景，还是从某一个垂直场景切入？如果是后者，第一个场景是什么？为什么？

### Q12：CN 如何处理「AI 生成内容的版权归属」问题？

当 AI 深度参与创作时，版权问题不可回避：

- CN 是否在 AI 生成的内容上做明确标注？
- 如果用户用 CN 写的小说出版了，AI 的贡献比例如何界定？
- 不同国家/地区的 AI 版权法规差异很大，CN 有没有法律合规方面的准备？

### Q13：如何防止 AI 输出与已有公开作品的内容雷同？

大语言模型可能在生成时「复述」训练数据中的内容。对于创作者来说，这是严重的风险：

- CN 是否有抄袭检测机制？
- 在风格迁移（如「用金庸风格重写」）时，如何确保输出是「风格相似」而非「段落抄袭」？

---

## 🔧 工程实现

### Q14：多模型支持策略是什么？

AI 行业变化极快，今天最好的模型可能半年后就被取代。

- CN 是绑定单一 API 提供商（如 OpenAI / Anthropic），还是设计了模型抽象层？
- 用户能否选择/切换自己偏好的模型？
- 不同 Agent（Writer / Editor / Lore Keeper）是否可以使用不同的模型？
- 是否支持本地模型（如 Ollama + 开源模型）以满足对隐私要求极高的用户？

### Q15：TipTap 编辑器能承载 CN 的全部交互需求吗？

TipTap 是一个优秀的富文本编辑器，但 CN 的交互远超常规编辑：

- AI Diff 视图（类似代码的 inline diff）在 TipTap 中如何实现？
- 审查报告的 inline 标注（在文本旁显示问题和建议）如何嵌入编辑器？
- 技能菜单、记忆面板、伏笔看板等 UI 元素如何与编辑器共存而不显拥挤？
- 是否评估过性能——在 50 万字的文档中，TipTap 的渲染和编辑性能如何？

### Q16：离线模式支持到什么程度？

CN 是 Electron 本地应用，但核心 AI 能力依赖远程 API。当用户离线时：

- 编辑和版本管理是否完全可用？
- 知识图谱浏览和本地规则检查是否可用？
- 是否有离线 AI 方案（本地模型回退）？
- 离线期间的编辑在恢复联网后如何同步记忆系统？

---

## 📊 数据与迭代

### Q17：如何衡量 CN 的「AI 辅助创作质量」？

这可能是最难回答的问题。创作质量是高度主观的。

- CN 用什么指标衡量 AI 输出质量？接受率？editDistance？用户满意度评分？
- 这些指标之间是否存在矛盾？（比如接受率高可能只是因为用户懒得改，而非真的满意）
- 是否有计划引入人类评估（如邀请专业编辑评价 AI 输出）？
- 如何建立一个可持续的质量反馈闭环？

### Q18：用户数据如何反哺产品迭代？

CN 是本地应用，用户数据不上传。但这也意味着：

- 无法通过用户行为数据来优化技能系统、改进 prompt
- 无法发现用户群体中的共性问题和需求

是否有 **opt-in 的匿名遥测方案**？如果有，收集哪些数据？如果没有，如何驱动产品迭代？

---

## 💰 商业化与竞争

### Q19：CN 的商业模式是什么？

AI 创作工具的商业模式选择直接影响产品设计：

- **一次性买断** → 用户无后续 AI 调用成本负担，但开发者收入不可持续
- **订阅制** → 稳定收入，但需要持续提供足够价值
- **按 token 计费** → 与 AI 成本直接挂钩，但用户可能因害怕花钱而减少使用 AI 功能
- **Freemium** → 基础功能免费 + 高级功能付费

CN 选择了哪种？背后的逻辑是什么？AI 调用成本（可能是最大的运营成本）如何分摊？

### Q20：面对 Cursor 等产品向创作领域扩展的风险，CN 的护城河是什么？

Cursor 已经证明了「IDE + AI」模式的市场价值。如果 Cursor 决定推出「Creative Mode」：

- CN 的哪些能力是 Cursor 短期内难以复制的？
- 知识图谱和记忆系统的数据积累是否构成用户迁移成本？
- 如果大模型的上下文窗口持续增大（比如到 10M tokens），分层上下文系统的价值会不会被削弱？
- CN 的长期壁垒到底是**技术**（分层上下文、知识图谱）、**数据**（记忆积累）、还是**社区**（创作者生态）？