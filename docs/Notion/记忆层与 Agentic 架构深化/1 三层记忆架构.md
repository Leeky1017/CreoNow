# 1. 三层记忆架构

<aside>
🎯

**核心思想**：记忆不是单一的"偏好数据库"，而是一个分层、分时、分粒度的认知系统。CN 的记忆架构模仿人类认知科学中的多存储模型，将记忆拆分为三个独立但互联的层级。

</aside>

---

## 架构总览

```
┌─────────────────────────────────────────────┐
│              Memory System                   │
│                                              │
│  ┌──────────┐  蒸馏   ┌──────────────────┐  │
│  │ Semantic  │ ◄───── │    Episodic      │  │
│  │ Memory    │        │    Memory         │  │
│  └──────────┘        └──────────────────┘  │
│       ▲                      ▲              │
│       │ 查询                  │ 归档         │
│       │                      │              │
│  ┌──────────────────────────────────────┐   │
│  │         Working Memory               │   │
│  │   (当前编辑会话的实时上下文)            │   │
│  └──────────────────────────────────────┘   │
└─────────────────────────────────────────────┘
```

---

## Layer 1：工作记忆（Working Memory）

### 定义

工作记忆是**当前编辑会话**中的实时上下文缓冲区。它不持久化到磁盘，会话结束时自动清除或压缩归档。

### 存储内容

| **数据类型** | **示例** | **生命周期** |
| --- | --- | --- |
| 当前编辑焦点 | 用户正在编辑第七章第三节 | 实时更新，焦点切换即替换 |
| 会话意图栈 | 用户在这次会话中主要在修改角色"林远"的对白风格 | 会话内累积，会话结束清除 |
| 撤销/重做缓冲 | 用户刚刚删除了一段对白，可能在重构场景 | 操作级别，随编辑器状态变化 |
| 临时偏好信号 | 用户在这次会话中连续三次选择了短句方案 | 会话内累积，未达阈值则丢弃 |
| AI 交互上下文 | 用户刚刚对 AI 续写的结果说"太啰嗦了" | 对话级别，随新对话刷新 |

### 技术实现要点

- **存储**：纯内存（Zustand store），不写入 SQLite
- **容量限制**：设定上限（如 8K tokens），采用 **滑动窗口 + 重要性加权** 策略裁剪
- **重要性评分**：每条记忆项有 `importance` 分数，由以下因素决定：
    - 与当前编辑焦点的语义相关度
    - 时间衰减（越近越重要）
    - 用户显式交互次数（被引用越多越重要）

### 与上下文引擎的关系

工作记忆直接喂入上下文引擎的 **Immediate 层**，是 AI 推理时最高优先级的记忆来源。

```tsx
interface WorkingMemory {
  currentFocus: EditingContext;      // 当前编辑焦点
  intentStack: UserIntent[];         // 会话意图栈
  undoBuffer: EditOperation[];       // 撤销缓冲
  tempSignals: PreferenceSignal[];   // 临时偏好信号
  aiDialogContext: DialogTurn[];     // AI 交互上下文
  
  // 容量管理
  tokenBudget: number;               // token 预算上限
  evict(): void;                     // 按重要性淘汰
}
```

---

## Layer 2：情景记忆（Episodic Memory）

### 定义

情景记忆记录**具体的、可回溯的交互事件**。它是记忆系统的核心数据来源，也是语义记忆蒸馏的原材料。

### 为什么情景记忆比直接学偏好更好？

<aside>
💡

**关键洞察**：人类学习不是通过抽象规则，而是通过具体经验。当一个编辑告诉作者"这段对白太长了"，作者记住的不是"对白要短"这个规则，而是"*那段*对白*为什么*太长了"这个具体经验。CN 的记忆系统应该模拟这种学习方式。

</aside>

### 情景结构（Episode Schema）

每个情景记忆是一个结构化记录：

```tsx
interface Episode {
  id: string;
  timestamp: number;
  
  // 触发上下文
  trigger: {
    skillUsed: string;             // 触发的技能（续写、改写等）
    inputContext: string;          // 输入上下文摘要
    projectId: string;             // 所属项目
    chapterId?: string;            // 所属章节
    sceneType?: string;            // 场景类型（对白、动作、描写等）
  };
  
  // AI 输出
  aiOutput: {
    candidates: string[];          // AI 生成的候选方案
    selectedIndex: number;         // 用户选择了哪个（-1 = 全部拒绝）
    finalText?: string;            // 用户最终采用的文本（可能在候选基础上手动修改）
  };
  
  // 用户反馈信号
  feedback: {
    explicit: string | null;       // 用户的显式评价（"太啰嗦""很好"）
    implicit: ImplicitSignal;      // 隐式信号（选择、修改幅度、响应时间）
    editDistance: number;           // 用户对 AI 输出的修改距离（0 = 完全接受）
  };
  
  // 元数据
  meta: {
    importance: number;            // 重要性评分
    recallCount: number;           // 被召回次数
    lastRecalledAt: number;        // 最后被召回的时间
    compressed: boolean;           // 是否已被压缩
  };
}
```

### 隐式反馈信号提取

用户的显式反馈（说"好"或"不好"）是稀疏的。系统需要从**隐式行为**中提取信号：

| **隐式信号** | **解读** | **权重** |
| --- | --- | --- |
| 用户直接接受 AI 输出，无修改 | 强正反馈 | 高 |
| 用户在 AI 输出基础上小幅修改（editDistance < 20%） | 弱正反馈，方向对但细节需调整 | 中 |
| 用户大幅改写 AI 输出（editDistance > 60%） | 弱负反馈，AI 方向有偏差 | 中 |
| 用户完全拒绝所有候选方案 | 强负反馈 | 高 |
| 用户撤销了之前接受的 AI 输出 | 延迟负反馈（可能是最有价值的信号） | 最高 |
| 用户反复对同类场景使用同一技能 | 场景-技能偏好信号 | 低（累积后变高） |

### 存储与索引

- **持久化**：SQLite，每个 Episode 一行
- **索引维度**：
    - 时间索引（按 timestamp）
    - 项目索引（按 projectId）
    - 场景类型索引（按 sceneType）
    - 语义索引（对 inputContext 做 embedding，存入向量索引）
- **召回方式**：当 AI 需要参考历史经验时，通过**场景类型 + 语义相似度**混合召回

---

## Layer 3：语义记忆（Semantic Memory）

### 定义

语义记忆是从情景记忆中**自动蒸馏**出来的抽象规律和偏好模型。它是稳定的、高密度的、可直接注入 prompt 的知识。

### 蒸馏过程

```
情景记忆（大量具体事件）
       │
       ▼
   聚类分析（按场景类型、技能类型分组）
       │
       ▼
   模式提取（统计显著的偏好模式）
       │
       ▼
   自然语言规则生成（"用户在动作场景中偏好短句，平均句长 < 15 字"）
       │
       ▼
   语义记忆条目（可直接注入 Rules 层）
```

### 语义记忆条目结构

```tsx
interface SemanticMemoryEntry {
  id: string;
  
  // 规则内容
  rule: string;                    // 自然语言描述
  category: 'style' | 'structure' | 'character' | 'pacing' | 'vocabulary';
  scope: 'global' | 'project';    // 全局偏好 or 项目特定
  
  // 置信度
  confidence: number;              // 0-1，基于支撑情景的数量和一致性
  supportingEpisodes: string[];    // 支撑此规则的情景 ID 列表
  contradictingEpisodes: string[]; // 与此规则矛盾的情景 ID 列表
  
  // 生命周期
  createdAt: number;
  updatedAt: number;
  version: number;                 // 规则被更新的次数
  
  // 用户确认状态
  userConfirmed: boolean;          // 用户是否在记忆面板中确认了此规则
  userModified: string | null;     // 用户手动修改后的版本
}
```

### 蒸馏触发条件

语义记忆的蒸馏**不是实时的**，而是在以下条件下触发：

1. **批量触发**：累积了 N 个新情景后（如每 50 个情景）
2. **空闲触发**：用户离开编辑器 > 5 分钟时，在后台执行
3. **手动触发**：用户在记忆面板中点击"更新偏好"
4. **冲突触发**：检测到新情景与现有语义记忆矛盾时

### 与上下文引擎的集成

语义记忆注入上下文引擎的 **Settings 层**，以自然语言规则的形式：

```
[User Writing Preferences - Auto-learned]
- 动作场景：偏好短句（平均 < 15 字），节奏紧凑，少用形容词（置信度: 0.87）
- 对白风格：口语化，避免书面语气，允许不完整句（置信度: 0.92）
- 描写偏好：视觉优先，少用嗅觉/味觉描写（置信度: 0.71）
- 叙事视角：严格第一人称，禁止全知视角泄露（置信度: 0.95，用户已确认）
```

---

## 三层记忆的协作流程

### 典型场景：用户请求续写一段打斗场景

1. **工作记忆**提供：当前章节上下文、用户刚刚修改的内容、本次会话的意图
2. **情景记忆**通过语义检索召回：过去 3 次用户在打斗场景中使用续写技能的记录——用户选择了哪些方案、做了什么修改
3. **语义记忆**注入规则：用户在动作场景中偏好短句、快节奏
4. 上下文引擎将三层记忆整合后喂入 AI，生成高度个性化的续写结果