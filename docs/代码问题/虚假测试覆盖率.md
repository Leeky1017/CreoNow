### 这是什么？

AI 写的测试看起来覆盖率很高（90%+），但实际上**只测了最简单的路径**，复杂的业务逻辑和真正容易出错的地方根本没有覆盖。

打个比方：你让人检查一栋楼的安全性，他检查了每扇门是否能打开，然后报告说「100% 的门都能打开，安全检查通过」。但他没有检查地基、电路、消防通道这些真正重要的东西。

### 🔍 具体表现

- **Happy path 测试**：只测「正常输入得到正常输出」的场景，不测错误处理
- **断言浅薄**：只检查「返回值不为空」，不检查返回值是否真的正确
- **重复测试**：同一个简单功能写了 5 个测试，复杂功能一个测试都没有
- **Mock 过度**：把所有依赖都用假的替代了，测试实际上**什么都没有真正测到**
- **测试名称具欺骗性**：测试叫「should handle edge case」，但里面测的根本不是边界情况
- **对 AI 生成代码的循环验证**：AI 写代码 → AI 写测试 → 测试当然通过（因为测试按代码逻辑写的，而不是按需求写的）

### ⚠️ 为什么有害？

1. **虚假安全感**：看到 90% 覆盖率以为代码很稳，实际上关键路径没有保护
2. **bug 漏网**：真正的问题藏在没测到的 10% 里，但你以为「都测过了」
3. **重构恐惧**：测试不可靠导致不敢改代码（因为改了不知道会不会出问题）
4. **在 CN 项目中的风险**：IPC 契约测试、并发读写、AI Provider 超时——这些才是需要深度测试的，而 AI 容易写一堆浅层断言糊弄过去

### ✅ Owner Review 要点

- [ ]  **不看覆盖率数字，看断言质量**：每个 `expect()` 都应该检查一个有意义的业务行为
- [ ]  要求 Agent：**先写失败场景的测试，再写成功场景**
- [ ]  在 [AGENTS.md](http://AGENTS.md) 中加入：*「每个测试必须包含至少一个错误路径的断言；禁止只检查返回值非空」*
- [ ]  对关键模块（IPC、文件 I/O、AI 调用）要求**集成测试**，不要只有单元测试
- [ ]  定期让 Agent 做**变异测试**：故意改坏代码，看现有测试能否发现