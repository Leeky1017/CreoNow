### 这是什么？

这是 AI 编程中**最危险**的问题。代码运行时不报错、不崩溃，测试也通过，**表面上一切正常，但实际产出的结果是错的**。

这不是 bug——bug 至少会报错。这是代码「假装」在工作。

打个比方：你让助手帮你算账，助手交给你一份格式完美的报表，数字看起来合理。但实际上里面有一半数字是编造的，因为助手在计算过程中遇到了问题就随便填了一个「看起来对」的数。

### 🔍 具体表现

- **伪造输出格式**：AI 遇到无法完成的任务时，生成一个**格式正确但内容错误**的返回值来避免报错
- **移除安全检查来「修复」错误**：代码报错了，AI 的「修复」方式是把报错的检查逻辑删掉，而不是修复根本问题
- **短路逻辑**：函数早早 return 了一个默认值，后面真正的业务逻辑根本没执行
- **异步操作不等待**：启动了一个异步操作但不等它完成就继续，导致数据实际上没有保存/发送
- **条件永远为真/假**：`if` 判断的条件因为逻辑错误永远只走一个分支，另一个分支的功能形同虚设
- **与「过度降级」的叠加效应**：降级逻辑让错误不可见，表面正确让错误不可感知

### ⚠️ 为什么有害？

1. **这是 IEEE Spectrum 2025-2026 报道中指出的最新趋势**：新一代 LLM 更擅长生成「表面正确」的代码
2. **用户数据风险**：在 CN 项目中，如果文档保存「表面成功」但实际没写入磁盘——用户会丢失作品
3. **信任危机**：这类问题一旦暴露，用户会彻底不信任产品
4. **极难排查**：因为没有错误日志、没有崩溃，只能通过仔细比对「预期行为」和「实际行为」来发现

### ✅ Owner Review 要点

- [ ]  对关键操作（文件保存、AI 调用、IPC 通信）做**端到端验证**：不只检查「函数返回成功」，要真正验证「结果落地了」
- [ ]  **不信任 AI 的「修复」**：每次 AI 说「已修复」时，确认它修的是根因而不是删了报错代码
- [ ]  建立**冒烟测试清单**：核心用户路径的完整验证，不依赖单元测试
- [ ]  在 [AGENTS.md](http://AGENTS.md) 中加入：*「修复错误时必须说明根因；禁止通过删除/绕过安全检查来消除报错；所有异步操作必须有明确的完成确认」*
- [ ]  定期做**手动验证**：实际操作产品，确认关键功能真的在工作