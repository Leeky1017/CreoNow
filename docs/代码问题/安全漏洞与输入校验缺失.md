### 这是什么？

AI 生成的代码默认**不做输入校验**——它假设所有输入数据都是「好的」。这意味着如果有人故意传入恶意数据，程序可能会做出完全不该做的事。

打个比方：你让人建了一个带锁的门，但门旁边的窗户没装玻璃。虽然门锁很结实，但小偷可以直接从窗户爬进来。

### 🔍 具体表现

- **缺少输入验证**：用户输入的数据（文件名、搜索词、配置项）没有被检查就直接使用
- **路径穿越风险**：文件操作时没有限制路径范围，恶意输入可以访问系统上任意文件
- **注入漏洞**：如果 CN 后续有数据库或命令行调用，AI 代码可能直接拼接用户输入，造成注入
- **敏感信息泄露**：错误信息中包含系统路径、内部配置、API 密钥等
- **使用过时的安全实践**：AI 的训练数据中包含旧的、不安全的代码模式，可能在新代码中复现
- **权限检查缺失**：操作前不验证用户是否有权限

### ⚠️ 为什么有害？

1. **Electron 应用的特殊风险**：CN 是 Electron 应用，主进程有系统级权限。如果渲染进程的输入没有校验，可能导致本地文件系统被越权访问
2. **API Key 安全**：AI Provider 的 Key 如果因为错误处理不当而暴露，会造成直接经济损失
3. **用户数据安全**：作为写作 IDE，用户的文稿是核心资产。任何安全漏洞都可能导致数据泄露或损坏
4. **学术研究证实**：即使明确要求「写安全代码」，AI 模型的输入校验仍然不一致

### ✅ Owner Review 要点

- [ ]  **IPC 通道是重点**：所有从渲染进程传到主进程的数据必须在主进程侧做校验
- [ ]  检查所有文件路径操作：必须限制在允许的目录范围内
- [ ]  在 [AGENTS.md](http://AGENTS.md) 中加入：*「所有外部输入必须校验；IPC 消息必须在主进程做参数验证；错误信息不得包含系统路径或密钥；文件操作必须限制在沙盒目录内」*
- [ ]  API Key 等敏感信息：检查是否存储在安全位置，是否可能通过日志或错误信息泄露
- [ ]  定期做一次**安全审计检查清单**的走查